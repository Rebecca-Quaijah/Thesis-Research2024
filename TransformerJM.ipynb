{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-29T19:05:08.905541Z",
     "start_time": "2024-11-29T19:05:06.439673Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Install TensorFlow if not already installed\n",
    "!pip install tensorflow pandas numpy\n",
    "!pip install patsy\n"
   ],
   "id": "10b8fe06909f7cc6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in /Users/esiboamah/miniconda3/lib/python3.12/site-packages (2.18.0)\r\n",
      "Requirement already satisfied: pandas in /Users/esiboamah/miniconda3/lib/python3.12/site-packages (2.2.2)\r\n",
      "Requirement already satisfied: numpy in /Users/esiboamah/miniconda3/lib/python3.12/site-packages (1.26.4)\r\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /Users/esiboamah/miniconda3/lib/python3.12/site-packages (from tensorflow) (2.1.0)\r\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /Users/esiboamah/miniconda3/lib/python3.12/site-packages (from tensorflow) (1.6.3)\r\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in /Users/esiboamah/miniconda3/lib/python3.12/site-packages (from tensorflow) (24.3.25)\r\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /Users/esiboamah/miniconda3/lib/python3.12/site-packages (from tensorflow) (0.6.0)\r\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /Users/esiboamah/miniconda3/lib/python3.12/site-packages (from tensorflow) (0.2.0)\r\n",
      "Requirement already satisfied: libclang>=13.0.0 in /Users/esiboamah/miniconda3/lib/python3.12/site-packages (from tensorflow) (18.1.1)\r\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /Users/esiboamah/miniconda3/lib/python3.12/site-packages (from tensorflow) (3.4.0)\r\n",
      "Requirement already satisfied: packaging in /Users/esiboamah/miniconda3/lib/python3.12/site-packages (from tensorflow) (23.1)\r\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /Users/esiboamah/miniconda3/lib/python3.12/site-packages (from tensorflow) (5.28.3)\r\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /Users/esiboamah/miniconda3/lib/python3.12/site-packages (from tensorflow) (2.31.0)\r\n",
      "Requirement already satisfied: setuptools in /Users/esiboamah/miniconda3/lib/python3.12/site-packages (from tensorflow) (68.2.2)\r\n",
      "Requirement already satisfied: six>=1.12.0 in /Users/esiboamah/miniconda3/lib/python3.12/site-packages (from tensorflow) (1.16.0)\r\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /Users/esiboamah/miniconda3/lib/python3.12/site-packages (from tensorflow) (2.5.0)\r\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /Users/esiboamah/miniconda3/lib/python3.12/site-packages (from tensorflow) (4.11.0)\r\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /Users/esiboamah/miniconda3/lib/python3.12/site-packages (from tensorflow) (1.17.0)\r\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /Users/esiboamah/miniconda3/lib/python3.12/site-packages (from tensorflow) (1.68.0)\r\n",
      "Requirement already satisfied: tensorboard<2.19,>=2.18 in /Users/esiboamah/miniconda3/lib/python3.12/site-packages (from tensorflow) (2.18.0)\r\n",
      "Requirement already satisfied: keras>=3.5.0 in /Users/esiboamah/miniconda3/lib/python3.12/site-packages (from tensorflow) (3.6.0)\r\n",
      "Requirement already satisfied: h5py>=3.11.0 in /Users/esiboamah/miniconda3/lib/python3.12/site-packages (from tensorflow) (3.12.1)\r\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /Users/esiboamah/miniconda3/lib/python3.12/site-packages (from tensorflow) (0.4.1)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/esiboamah/miniconda3/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/esiboamah/miniconda3/lib/python3.12/site-packages (from pandas) (2024.1)\r\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/esiboamah/miniconda3/lib/python3.12/site-packages (from pandas) (2023.3)\r\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /Users/esiboamah/miniconda3/lib/python3.12/site-packages (from astunparse>=1.6.0->tensorflow) (0.41.2)\r\n",
      "Requirement already satisfied: rich in /Users/esiboamah/miniconda3/lib/python3.12/site-packages (from keras>=3.5.0->tensorflow) (13.9.4)\r\n",
      "Requirement already satisfied: namex in /Users/esiboamah/miniconda3/lib/python3.12/site-packages (from keras>=3.5.0->tensorflow) (0.0.8)\r\n",
      "Requirement already satisfied: optree in /Users/esiboamah/miniconda3/lib/python3.12/site-packages (from keras>=3.5.0->tensorflow) (0.13.1)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/esiboamah/miniconda3/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (2.0.4)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/esiboamah/miniconda3/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (3.4)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/esiboamah/miniconda3/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (2.1.0)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/esiboamah/miniconda3/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (2024.8.30)\r\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Users/esiboamah/miniconda3/lib/python3.12/site-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.7)\r\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /Users/esiboamah/miniconda3/lib/python3.12/site-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\r\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /Users/esiboamah/miniconda3/lib/python3.12/site-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.3)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /Users/esiboamah/miniconda3/lib/python3.12/site-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (2.1.3)\r\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /Users/esiboamah/miniconda3/lib/python3.12/site-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\r\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/esiboamah/miniconda3/lib/python3.12/site-packages (from rich->keras>=3.5.0->tensorflow) (2.15.1)\r\n",
      "Requirement already satisfied: mdurl~=0.1 in /Users/esiboamah/miniconda3/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\r\n",
      "Requirement already satisfied: patsy in /Users/esiboamah/miniconda3/lib/python3.12/site-packages (1.0.1)\r\n",
      "Requirement already satisfied: numpy>=1.4 in /Users/esiboamah/miniconda3/lib/python3.12/site-packages (from patsy) (1.26.4)\r\n"
     ]
    }
   ],
   "execution_count": 107
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-11-29T19:05:10.494549Z",
     "start_time": "2024-11-29T19:05:10.490853Z"
    }
   },
   "source": [
    "# Import necessary libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, Model\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from patsy import dmatrix"
   ],
   "outputs": [],
   "execution_count": 108
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-29T19:05:12.305372Z",
     "start_time": "2024-11-29T19:05:12.298806Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from patsy import dmatrix\n",
    "\n",
    "def get_tensors(\n",
    "    df, \n",
    "    long=[\"serBilir\"],       # Longitudinal outcome\n",
    "    base=[\"age\", \"sex\", \"drug\"],  # Baseline covariates\n",
    "    obstime=\"year\",          # Observation time column\n",
    "    spline_degree=3,         # Degree for natural spline\n",
    "    df_spline=5              # Degrees of freedom for spline\n",
    "):\n",
    "    \"\"\"\n",
    "    Convert DataFrame to TensorFlow tensors for Transformer model.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : Pandas DataFrame\n",
    "        Input data with longitudinal, baseline covariates, and observation times.\n",
    "    long : list of str\n",
    "        Columns for longitudinal outcomes.\n",
    "    base : list of str\n",
    "        Columns for baseline covariates.\n",
    "    obstime : str\n",
    "        Column for observation time.\n",
    "    spline_degree : int\n",
    "        Degree of the natural spline for the time-varying component.\n",
    "    df_spline : int\n",
    "        Degrees of freedom for the natural spline.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Tensors for Transformer input: x_long, x_base, mask, event_tensor, time_tensor, obs_time\n",
    "    \"\"\"\n",
    "    # Convert categorical columns to numerical encodings\n",
    "    if \"sex\" in df:\n",
    "        df[\"sex\"] = df[\"sex\"].astype(\"category\").cat.codes\n",
    "    if \"drug\" in df:\n",
    "        df[\"drug\"] = df[\"drug\"].astype(\"category\").cat.codes\n",
    "\n",
    "    # Add subject indices\n",
    "    df[\"id_new\"] = df.groupby(\"id\").ngroup()\n",
    "\n",
    "    # Generate natural spline features for `obstime`\n",
    "    spline_features = dmatrix(\n",
    "        f\"bs({obstime}, df={df_spline}, degree={spline_degree}, include_intercept=False)\", \n",
    "        data=df, \n",
    "        return_type=\"dataframe\"\n",
    "    )\n",
    "\n",
    "    # Add spline features to the DataFrame\n",
    "    spline_columns = [f\"spline_{i}\" for i in range(spline_features.shape[1])]\n",
    "    df[spline_columns] = spline_features\n",
    "\n",
    "    # Update baseline covariates to include spline features\n",
    "    base += spline_columns\n",
    "\n",
    "    # Determine tensor dimensions\n",
    "    num_subjects = df[\"id_new\"].nunique()\n",
    "    max_visits = df.groupby(\"id\")[\"year\"].count().max()\n",
    "\n",
    "    # Initialize tensors\n",
    "    x_base = tf.zeros((num_subjects, max_visits, len(base)), dtype=tf.float32)\n",
    "    x_long = tf.zeros((num_subjects, max_visits, len(long)), dtype=tf.float32)\n",
    "    mask = tf.zeros((num_subjects, max_visits), dtype=tf.bool)\n",
    "    obs_time = tf.zeros((num_subjects, max_visits), dtype=tf.float32)\n",
    "\n",
    "    # Populate tensors\n",
    "    for _, row in df.iterrows():\n",
    "        subj_idx = int(row[\"id_new\"])\n",
    "        visit_idx = int(row[\"year\"])\n",
    "        \n",
    "        # Populate baseline covariates\n",
    "        x_base = tf.tensor_scatter_nd_update(\n",
    "            x_base, [[subj_idx, visit_idx]], [row[base].values]\n",
    "        )\n",
    "        \n",
    "        # Populate longitudinal outcomes\n",
    "        x_long = tf.tensor_scatter_nd_update(\n",
    "            x_long, [[subj_idx, visit_idx]], [row[long].values]\n",
    "        )\n",
    "        \n",
    "        # Populate observation time and mask\n",
    "        mask = tf.tensor_scatter_nd_update(mask, [[subj_idx, visit_idx]], [True])\n",
    "        obs_time = tf.tensor_scatter_nd_update(\n",
    "            obs_time, [[subj_idx, visit_idx]], [row[obstime]]\n",
    "        )\n",
    "\n",
    "    # Extract event and time tensors\n",
    "    event_tensor = tf.convert_to_tensor(\n",
    "        df[df[\"year\"] == 0][\"status2\"].values, dtype=tf.float32\n",
    "    )\n",
    "    time_tensor = tf.convert_to_tensor(\n",
    "        df[df[\"year\"] == 0][\"years\"].values, dtype=tf.float32\n",
    "    )\n",
    "\n",
    "    return x_long, x_base, mask, event_tensor, time_tensor, obs_time\n"
   ],
   "id": "77133b52c6e3e48c",
   "outputs": [],
   "execution_count": 110
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-29T19:05:13.874981Z",
     "start_time": "2024-11-29T19:05:12.960761Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from patsy import dmatrix\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"pbc2_dataset.csv\")  # Replace with the correct path to your dataset\n",
    "\n",
    "# Call the function\n",
    "x_long, x_base, mask, event_tensor, time_tensor, obs_time = get_tensors(\n",
    "    df,\n",
    "    long=[\"serBilir\"],       # Longitudinal outcome\n",
    "    base=[\"age\", \"sex\", \"drug\"],  # Baseline covariates\n",
    "    obstime=\"year\",          # Observation time column\n",
    "    spline_degree=3,      # Degree for natural spline\n",
    "     df_spline=3   \n",
    ")\n",
    "\n",
    "# View outputs\n",
    "print(\"Longitudinal Covariates Tensor (x_long):\")\n",
    "print(x_long.numpy())\n",
    "\n",
    "print(\"\\nBaseline Covariates Tensor (x_base):\")\n",
    "print(x_base.numpy())\n",
    "\n",
    "print(\"\\nMask Tensor (mask):\")\n",
    "print(mask.numpy())\n",
    "\n",
    "print(\"\\nEvent Indicator Tensor (event_tensor):\")\n",
    "print(event_tensor.numpy())\n",
    "\n",
    "print(\"\\nEvent Time Tensor (time_tensor):\")\n",
    "print(time_tensor.numpy())\n",
    "\n",
    "print(\"\\nObservation Time Tensor (obs_time):\")\n",
    "print(obs_time.numpy())\n"
   ],
   "id": "96b6146d4c24d4e1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Longitudinal Covariates Tensor (x_long):\n",
      "[[[21.3]\n",
      "  [ 0. ]\n",
      "  [ 0. ]\n",
      "  ...\n",
      "  [ 0. ]\n",
      "  [ 0. ]\n",
      "  [ 0. ]]\n",
      "\n",
      " [[ 1. ]\n",
      "  [ 0. ]\n",
      "  [ 1.9]\n",
      "  ...\n",
      "  [ 0. ]\n",
      "  [ 0. ]\n",
      "  [ 0. ]]\n",
      "\n",
      " [[ 1.5]\n",
      "  [ 0. ]\n",
      "  [ 1.8]\n",
      "  ...\n",
      "  [ 0. ]\n",
      "  [ 0. ]\n",
      "  [ 0. ]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 1.7]\n",
      "  [ 2.2]\n",
      "  [ 1.4]\n",
      "  ...\n",
      "  [ 0. ]\n",
      "  [ 0. ]\n",
      "  [ 0. ]]\n",
      "\n",
      " [[ 1.5]\n",
      "  [ 1.9]\n",
      "  [ 0. ]\n",
      "  ...\n",
      "  [ 0. ]\n",
      "  [ 0. ]\n",
      "  [ 0. ]]\n",
      "\n",
      " [[ 5.5]\n",
      "  [ 7.4]\n",
      "  [23.4]\n",
      "  ...\n",
      "  [ 0. ]\n",
      "  [ 0. ]\n",
      "  [ 0. ]]]\n",
      "\n",
      "Baseline Covariates Tensor (x_base):\n",
      "[[[5.87668381e+01 0.00000000e+00 0.00000000e+00 ... 1.03623502e-01\n",
      "   4.01123241e-03 5.17578374e-05]\n",
      "  [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "   0.00000000e+00 0.00000000e+00]\n",
      "  [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "   0.00000000e+00 0.00000000e+00]\n",
      "  ...\n",
      "  [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "   0.00000000e+00 0.00000000e+00]\n",
      "  [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "   0.00000000e+00 0.00000000e+00]\n",
      "  [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "   0.00000000e+00 0.00000000e+00]]\n",
      "\n",
      " [[5.64478149e+01 0.00000000e+00 0.00000000e+00 ... 1.83490425e-01\n",
      "   1.39908092e-02 3.55591212e-04]\n",
      "  [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "   0.00000000e+00 0.00000000e+00]\n",
      "  [5.64478149e+01 0.00000000e+00 0.00000000e+00 ... 3.23814273e-01\n",
      "   5.67265898e-02 3.31250159e-03]\n",
      "  ...\n",
      "  [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "   0.00000000e+00 0.00000000e+00]\n",
      "  [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "   0.00000000e+00 0.00000000e+00]\n",
      "  [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "   0.00000000e+00 0.00000000e+00]]\n",
      "\n",
      " [[7.00744705e+01 1.00000000e+00 0.00000000e+00 ... 1.83064178e-01\n",
      "   1.39171593e-02 3.52676550e-04]\n",
      "  [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "   0.00000000e+00 0.00000000e+00]\n",
      "  [7.00744705e+01 1.00000000e+00 0.00000000e+00 ... 3.16856563e-01\n",
      "   5.33963330e-02 2.99943099e-03]\n",
      "  ...\n",
      "  [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "   0.00000000e+00 0.00000000e+00]\n",
      "  [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "   0.00000000e+00 0.00000000e+00]\n",
      "  [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "   0.00000000e+00 0.00000000e+00]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[6.23343544e+01 0.00000000e+00 0.00000000e+00 ... 1.36502296e-01\n",
      "   7.25482311e-03 1.28526444e-04]\n",
      "  [6.23343544e+01 0.00000000e+00 0.00000000e+00 ... 2.80340850e-01\n",
      "   3.85631137e-02 1.76822115e-03]\n",
      "  [6.23343544e+01 0.00000000e+00 0.00000000e+00 ... 3.75813246e-01\n",
      "   8.91699046e-02 7.05250306e-03]\n",
      "  ...\n",
      "  [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "   0.00000000e+00 0.00000000e+00]\n",
      "  [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "   0.00000000e+00 0.00000000e+00]\n",
      "  [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "   0.00000000e+00 0.00000000e+00]]\n",
      "\n",
      " [[3.79996719e+01 0.00000000e+00 0.00000000e+00 ... 1.01128556e-01\n",
      "   3.80886998e-03 4.78186448e-05]\n",
      "  [3.79996719e+01 0.00000000e+00 0.00000000e+00 ... 1.96917921e-01\n",
      "   1.64408870e-02 4.57555696e-04]\n",
      "  [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "   0.00000000e+00 0.00000000e+00]\n",
      "  ...\n",
      "  [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "   0.00000000e+00 0.00000000e+00]\n",
      "  [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "   0.00000000e+00 0.00000000e+00]\n",
      "  [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "   0.00000000e+00 0.00000000e+00]]\n",
      "\n",
      " [[3.31535416e+01 0.00000000e+00 1.00000000e+00 ... 1.10552646e-01\n",
      "   4.60449746e-03 6.39254940e-05]\n",
      "  [3.31535416e+01 0.00000000e+00 1.00000000e+00 ... 1.94015786e-01\n",
      "   1.58895757e-02 4.33776731e-04]\n",
      "  [3.31535416e+01 0.00000000e+00 1.00000000e+00 ... 3.91997755e-01\n",
      "   1.03359722e-01 9.08443332e-03]\n",
      "  ...\n",
      "  [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "   0.00000000e+00 0.00000000e+00]\n",
      "  [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "   0.00000000e+00 0.00000000e+00]\n",
      "  [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "   0.00000000e+00 0.00000000e+00]]]\n",
      "\n",
      "Mask Tensor (mask):\n",
      "[[ True False False ... False False False]\n",
      " [ True False  True ... False False False]\n",
      " [ True False  True ... False False False]\n",
      " ...\n",
      " [ True  True  True ... False False False]\n",
      " [ True  True False ... False False False]\n",
      " [ True  True  True ... False False False]]\n",
      "\n",
      "Event Indicator Tensor (event_tensor):\n",
      "[1. 0. 1. 1. 0. 1. 0. 1. 1. 1. 1. 1. 0. 1. 1. 0. 1. 1. 0. 1. 1. 1. 1. 1.\n",
      " 0. 1. 1. 1. 1. 1. 1. 0. 1. 0. 1. 0. 1. 1. 1. 0. 1. 0. 0. 1. 0. 1. 0. 0.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 0. 0. 1. 1. 1. 0. 1. 1. 0. 1. 1. 0. 0.\n",
      " 0. 1. 1. 1. 1. 1. 0. 1. 1. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 0.\n",
      " 1. 0. 0. 1. 0. 0. 1. 1. 0. 1. 0. 1. 0. 1. 0. 1. 1. 1. 0. 0. 1. 1. 1. 0.\n",
      " 1. 0. 1. 1. 0. 1. 0. 1. 0. 1. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1.\n",
      " 0. 1. 1. 1. 1. 0. 0. 1. 0. 1. 0. 1. 0. 0. 1. 0. 0. 1. 1. 1. 1. 0. 1. 0.\n",
      " 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 0. 0. 0. 1. 0.\n",
      " 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 0.\n",
      " 1. 0. 0. 1. 0. 1. 1. 0. 0. 0. 1. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 1. 1. 0.\n",
      " 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.\n",
      " 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.\n",
      " 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "\n",
      "Event Time Tensor (time_tensor):\n",
      "[ 1.0951703  14.152338    2.7707808   5.270507    4.1205783   6.8530283\n",
      "  6.8475523   6.7517247   6.5710216   0.1396342  10.3000765   0.83232945\n",
      " 11.627971    3.3320556   9.812726   11.896287    2.105465    0.3614062\n",
      " 13.418574    3.7126274  10.012594    1.8426241   0.7228124  11.167999\n",
      " 13.131092    3.953565    0.21082029  1.5031213  13.892235    0.8788742\n",
      " 10.510897   14.21531     8.679225   12.599935    7.7948747  11.72106\n",
      "  0.61055744  8.881831    6.2890153  14.061987    3.6961997  14.023656\n",
      " 14.305662    9.38561    12.851824    6.1767607   8.884569   13.95247\n",
      "  1.9384514   7.113131   10.549228    6.532691    2.7379258   3.9261856\n",
      "  3.723579    5.0569487   8.985872   14.040083    6.089147   13.782719\n",
      " 13.484284    8.460191    2.3518782   4.0712957  13.257036   11.474647\n",
      "  7.5813165  12.890155    3.2033732  10.08378    13.320009   13.287153\n",
      " 13.303581    5.00219     3.2608695   0.19439273  0.8925638   4.6270947\n",
      " 11.981163    2.436754    6.9543314   9.785347   12.920272   12.870989\n",
      "  9.193954    4.536743    0.5421093   8.42186     4.766729    7.3622823\n",
      "  1.2594458   1.0650531  12.547914    2.0534444   0.3750958  12.375424\n",
      "  1.6975139  12.298762   12.290548    1.511335   11.636185   10.32198\n",
      "  0.30117184  8.449239    8.465667    8.821597   11.110502    7.072062\n",
      "  8.687438    5.59632     6.4341254   9.432155    2.6037674   9.295258\n",
      " 11.200854   10.992772    2.9651735   6.2643743   1.4100318   5.566203\n",
      "  0.5229438  10.858614    2.658526   10.686124    6.7572007   2.2560508\n",
      " 10.743621    2.839229   10.699814    3.8632133   2.327237    9.892126\n",
      "  7.6552405  10.453401   10.456139   10.3137665  10.01807     3.5510898\n",
      "  6.453291   10.206987   10.182345    6.6230426   2.1520097   2.5873399\n",
      "  9.979739    8.449239    9.259665    3.90702     2.0862994   9.747016\n",
      "  9.689519    3.1540904   9.670354    0.3833096   9.626547    2.3354506\n",
      "  9.593692    6.776366    4.205454    9.421203    9.489651    0.5092542\n",
      "  5.626437    0.7556675   2.9460082   9.281569    4.6106668   9.265141\n",
      "  3.318366    9.202168    8.879093    8.1316395   9.106341    9.070748\n",
      "  9.015989    4.0849853   8.97492     8.895521    8.876355    8.848976\n",
      "  8.82981     8.827072    6.1356916   2.6667397   7.890702    4.314971\n",
      "  2.0068996   7.214434    8.556018    8.687438    0.591392    8.520425\n",
      "  2.1821268   8.536853    8.21104     6.9954004   8.306867    8.282226\n",
      "  8.189136    8.027598    8.112474    8.052239    7.9126053   5.722265\n",
      "  5.6976233   8.005695    7.775709    2.4750848   7.90713     7.9208193\n",
      "  7.844157    7.7893987   5.9933195   4.8899355   2.9569597   6.3957944\n",
      "  2.1629612   7.772971    7.737378    3.3813384   7.4444203   1.6345416\n",
      "  0.9144672   7.156938    7.3677583   7.2472897   2.7351878   7.217172\n",
      "  0.9527982   7.250027    3.1896834   7.1733656   7.121345    6.6942286\n",
      "  6.3027053   7.0556345   5.3307414   5.1308727   1.9001205   6.8448143\n",
      "  2.2916439   5.826306    2.5462708   4.6270947   6.732559    3.9289234\n",
      "  2.5736501   6.7188697   6.713394    6.3711534   6.316395    6.677801\n",
      "  6.664111    2.0178514   6.5847116   6.488884    6.2506843   6.491622\n",
      "  6.2534223   4.5832877   6.4286494   5.0651627   3.5675173   4.2218814\n",
      "  2.9679115   6.2616363   0.4900887   3.2608695   5.1965833   5.5032306\n",
      "  6.1274776   6.007009    4.5148396   3.9617786   5.53061     5.8783264\n",
      "  5.763334    5.4649      5.75512     5.6976233   0.11225495  4.5805497\n",
      "  5.7359543   5.7140512   5.667506    5.6866717   4.249261    2.9213667\n",
      "  2.1876028   5.563465    2.466871    4.8871975   5.4457345   5.3964515\n",
      "  2.395685    5.448472    1.4593145   5.390976    5.3718104   0.56675065\n",
      "  5.390976    5.311576    4.3724675   5.199321    5.16099     5.16099\n",
      "  4.977549    4.9885006   4.5531707   4.4025846   4.128792    3.989158  ]\n",
      "\n",
      "Observation Time Tensor (obs_time):\n",
      "[[0.52568173 0.         0.         ... 0.         0.         0.        ]\n",
      " [0.9993429  0.         2.102727   ... 0.         0.         0.        ]\n",
      " [0.996605   0.         2.0342789  ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.7118607  1.7057277  2.7050707  ... 0.         0.         0.        ]\n",
      " [0.5119921  1.0869565  0.         ... 0.         0.         0.        ]\n",
      " [0.5640127  1.067791   2.9432702  ... 0.         0.         0.        ]]\n"
     ]
    }
   ],
   "execution_count": 111
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-29T19:05:14.911732Z",
     "start_time": "2024-11-29T19:05:14.909934Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "5656c7a592973e3b",
   "outputs": [],
   "execution_count": 111
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-29T19:05:15.640912Z",
     "start_time": "2024-11-29T19:05:15.628069Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_mask(pad, future=True, window=None):\n",
    "    \"\"\"\n",
    "    Create attention masks for padding and future lookahead.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    pad : Tensor\n",
    "        Padding tensor indicating non-padded elements.\n",
    "    future : bool\n",
    "        If True, prevent attention to future time steps.\n",
    "    window : int\n",
    "        Optional sliding window for attention.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    mask : Tensor\n",
    "        Attention mask for the Transformer.\n",
    "    \"\"\"\n",
    "    size = tf.shape(pad)[1]\n",
    "    mask = tf.expand_dims(tf.cast(pad != 0, tf.float32), axis=1)  # Padding mask\n",
    "\n",
    "    if future:\n",
    "        future_mask = tf.linalg.band_part(tf.ones((size, size)), 0, -1)\n",
    "        if window is not None:\n",
    "            window_mask = tf.linalg.band_part(tf.ones((size, size)), -window, 0)\n",
    "            future_mask *= window_mask\n",
    "        mask = mask * tf.expand_dims(future_mask, axis=0)\n",
    "\n",
    "    # Expand mask to align with multi-head attention shape\n",
    "    return tf.expand_dims(mask, axis=1)  # (batch_size, 1, seq_len, seq_len)\n"
   ],
   "id": "afb7a061ea2c5f6b",
   "outputs": [],
   "execution_count": 112
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-29T19:05:16.645589Z",
     "start_time": "2024-11-29T19:05:16.643901Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "50c8d22fcad14668",
   "outputs": [],
   "execution_count": 112
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-29T19:12:52.662388Z",
     "start_time": "2024-11-29T19:12:52.653772Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class NoamOpt(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "    def __init__(self, model_size, warmup_steps, factor=1):\n",
    "        self.model_size = tf.cast(model_size, tf.float32)\n",
    "        self.warmup_steps = tf.cast(warmup_steps, tf.float32)\n",
    "        self.factor = factor\n",
    "\n",
    "    def __call__(self, step):\n",
    "        step = tf.cast(step, tf.float32)\n",
    "        rate = self.factor * (self.model_size ** -0.5) * tf.minimum(\n",
    "            step ** -0.5, step * (self.warmup_steps ** -1.5)\n",
    "        )\n",
    "        return rate\n"
   ],
   "id": "694a12c56146256",
   "outputs": [],
   "execution_count": 120
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-29T19:12:53.444307Z",
     "start_time": "2024-11-29T19:12:53.442360Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "98a5bdfdeda899d7",
   "outputs": [],
   "execution_count": 120
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-29T19:12:54.027904Z",
     "start_time": "2024-11-29T19:12:54.021399Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "\n",
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, nhead, dropout=0.1):\n",
    "        \"\"\"\n",
    "        Multi-Head Attention layer for Transformer.\n",
    "\n",
    "        Parameters:\n",
    "        ----------\n",
    "        d_model: int\n",
    "            Total dimension of the model (embedding size).\n",
    "        nhead: int\n",
    "            Number of attention heads.\n",
    "        dropout: float\n",
    "            Dropout rate.\n",
    "        \"\"\"\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.d_model = d_model\n",
    "        self.nhead = nhead\n",
    "        self.d_k = d_model // nhead\n",
    "\n",
    "        assert d_model % nhead == 0, \"d_model must be divisible by nhead\"\n",
    "\n",
    "        # Linear layers for query, key, value transformations\n",
    "        self.q_linear = tf.keras.layers.Dense(d_model, use_bias=False)\n",
    "        self.k_linear = tf.keras.layers.Dense(d_model, use_bias=False)\n",
    "        self.v_linear = tf.keras.layers.Dense(d_model, use_bias=False)\n",
    "        self.out = tf.keras.layers.Dense(d_model)\n",
    "\n",
    "        self.dropout = tf.keras.layers.Dropout(dropout)\n",
    "\n",
    "    def attention(self, query, key, value, d_k, mask=None):\n",
    "        \"\"\"\n",
    "        Scaled Dot-Product Attention.\n",
    "\n",
    "        Parameters:\n",
    "        ----------\n",
    "        query, key, value: Tensors of shape (batch_size, seq_len, d_k)\n",
    "        d_k: int\n",
    "            Dimension of key vectors.\n",
    "        mask: Tensor, optional\n",
    "            Mask to ignore certain time steps, shape (batch_size, seq_len).\n",
    "\n",
    "        Returns:\n",
    "        -------\n",
    "        output: Tensor\n",
    "            Attention output.\n",
    "        \"\"\"\n",
    "        scores = tf.matmul(query, key, transpose_b=True) / np.sqrt(d_k)\n",
    "\n",
    "        # Apply mask if provided\n",
    "        if mask is not None:\n",
    "            scores += (mask * -1e9)  # Large negative value to ignore\n",
    "\n",
    "        # Softmax normalization\n",
    "        scores = tf.nn.softmax(scores, axis=-1)\n",
    "\n",
    "        # Apply dropout\n",
    "        scores = self.dropout(scores)\n",
    "\n",
    "        # Weighted sum of values\n",
    "        output = tf.matmul(scores, value)\n",
    "        return output\n",
    "\n",
    "    def call(self, query, key, value, mask=None):\n",
    "        \"\"\"\n",
    "        Forward pass for Multi-Head Attention.\n",
    "\n",
    "        Parameters:\n",
    "        ----------\n",
    "        query, key, value: Tensors of shape (batch_size, seq_len, d_model)\n",
    "        mask: Tensor, optional\n",
    "            Mask for padding or future steps.\n",
    "\n",
    "        Returns:\n",
    "        -------\n",
    "        output: Tensor\n",
    "            Multi-head attention output, shape (batch_size, seq_len, d_model).\n",
    "        \"\"\"\n",
    "        batch_size = tf.shape(query)[0]\n",
    "\n",
    "        # Linear projections\n",
    "        query = self.q_linear(query)  # (batch_size, seq_len, d_model)\n",
    "        key = self.k_linear(key)\n",
    "        value = self.v_linear(value)\n",
    "\n",
    "        # Split into multiple heads and reshape\n",
    "        query = tf.reshape(query, (batch_size, -1, self.nhead, self.d_k))  # (batch_size, seq_len, nhead, d_k)\n",
    "        key = tf.reshape(key, (batch_size, -1, self.nhead, self.d_k))\n",
    "        value = tf.reshape(value, (batch_size, -1, self.nhead, self.d_k))\n",
    "\n",
    "        # Transpose to (batch_size, nhead, seq_len, d_k)\n",
    "        query = tf.transpose(query, perm=[0, 2, 1, 3])\n",
    "        key = tf.transpose(key, perm=[0, 2, 1, 3])\n",
    "        value = tf.transpose(value, perm=[0, 2, 1, 3])\n",
    "\n",
    "        # Apply attention\n",
    "        scores = self.attention(query, key, value, self.d_k, mask)\n",
    "\n",
    "        # Concatenate heads and reshape back to (batch_size, seq_len, d_model)\n",
    "        scores = tf.transpose(scores, perm=[0, 2, 1, 3])  # (batch_size, seq_len, nhead, d_k)\n",
    "        concat = tf.reshape(scores, (batch_size, -1, self.d_model))\n",
    "\n",
    "        # Final linear layer\n",
    "        output = self.out(concat)\n",
    "        return output\n"
   ],
   "id": "ba0c2fb1466e31fa",
   "outputs": [],
   "execution_count": 121
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-29T19:12:54.820091Z",
     "start_time": "2024-11-29T19:12:54.818425Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "4825ab21e99afcc",
   "outputs": [],
   "execution_count": 121
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-29T19:12:55.236603Z",
     "start_time": "2024-11-29T19:12:55.233643Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "79825235ef4729b4",
   "outputs": [],
   "execution_count": 121
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-29T19:12:55.830077Z",
     "start_time": "2024-11-29T19:12:55.826921Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "7fa40233919a26e1",
   "outputs": [],
   "execution_count": 121
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-29T19:12:56.552902Z",
     "start_time": "2024-11-29T19:12:56.539069Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, LayerNormalization, Dropout\n",
    "from tensorflow.keras import Sequential\n",
    "\n",
    "\n",
    "class DecoderLayer(tf.keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    Transformer Decoder Layer\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    d_model : int\n",
    "        Dimension of the input vector (embedding size).\n",
    "    nhead : int\n",
    "        Number of attention heads.\n",
    "    dropout : float\n",
    "        Dropout rate.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, d_model, nhead, dropout=0.1):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "        self.dropout = Dropout(dropout)\n",
    "        \n",
    "        # Multi-Head Attention\n",
    "        self.attention = MultiHeadAttention(d_model, nhead, dropout)\n",
    "        \n",
    "        # Feed-Forward Network\n",
    "        self.feed_forward = Sequential([\n",
    "            Dense(64, activation='relu'),\n",
    "            Dense(d_model),\n",
    "            Dropout(dropout)\n",
    "        ])\n",
    "        \n",
    "        # Layer Normalization\n",
    "        self.layer_norm1 = LayerNormalization(epsilon=1e-6)\n",
    "        self.layer_norm2 = LayerNormalization(epsilon=1e-6)\n",
    "    \n",
    "    def call(self, q, kv, mask, training=False):\n",
    "        \"\"\"\n",
    "        Forward pass for the decoder layer.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        q : tf.Tensor\n",
    "            Query tensor (e.g., target sequence), shape (batch_size, seq_len, d_model).\n",
    "        kv : tf.Tensor\n",
    "            Key-Value tensor (e.g., source sequence), shape (batch_size, seq_len, d_model).\n",
    "        mask : tf.Tensor\n",
    "            Attention mask.\n",
    "        training : bool\n",
    "            If True, applies dropout.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        x : tf.Tensor\n",
    "            Processed output tensor, shape (batch_size, seq_len, d_model).\n",
    "        \"\"\"\n",
    "        # Attention Block\n",
    "        residual = q\n",
    "        x = self.attention(query=q, key=kv, value=kv, mask=mask)  # Multi-Head Attention\n",
    "        x = self.dropout(x, training=training)\n",
    "        x = self.layer_norm1(x + residual)  # Add & Norm\n",
    "        \n",
    "        # Feed-Forward Block\n",
    "        residual = x\n",
    "        x = self.feed_forward(x, training=training)\n",
    "        x = self.layer_norm2(x + residual)  # Add & Norm\n",
    "        \n",
    "        return x\n"
   ],
   "id": "90e2753413aa0aeb",
   "outputs": [],
   "execution_count": 122
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-29T19:12:57.474629Z",
     "start_time": "2024-11-29T19:12:57.472412Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "dc59d9e955467178",
   "outputs": [],
   "execution_count": 122
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-29T19:12:58.046613Z",
     "start_time": "2024-11-29T19:12:58.041849Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "def positional_encoding(batch_size, length, d_model, obs_time):\n",
    "    \"\"\"\n",
    "    Positional Encoding for each visit.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    batch_size : int\n",
    "        Number of subjects in batch.\n",
    "    length : int\n",
    "        Number of visits.\n",
    "    d_model : int\n",
    "        Dimension of the model vector.\n",
    "    obs_time : tf.Tensor\n",
    "        Observed/recorded time of each visit, shape (batch_size, length) or (length).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    PE : tf.Tensor\n",
    "        Positional encodings, shape (batch_size, length, d_model).\n",
    "    \"\"\"\n",
    "    # Ensure obs_time has consistent shape\n",
    "    if tf.rank(obs_time) == 0:  # Scalar\n",
    "        obs_time = tf.expand_dims(tf.repeat(obs_time, batch_size), axis=1)\n",
    "    elif tf.rank(obs_time) == 1:  # 1D tensor\n",
    "        obs_time = tf.tile(tf.expand_dims(obs_time, axis=0), [batch_size, 1])\n",
    "\n",
    "    # Initialize positional encoding matrix\n",
    "    PE = tf.zeros((batch_size, length, d_model), dtype=tf.float32)\n",
    "\n",
    "    # Compute positional encoding for even indices\n",
    "    even_indices = tf.cast(tf.range(0, d_model, 2), dtype=tf.float32)  # Cast to float32\n",
    "    even_angles = tf.pow(10000.0, even_indices / d_model)\n",
    "    PE_even = tf.sin(tf.einsum('ij,k->ijk', obs_time, 1 / even_angles))\n",
    "\n",
    "    # Compute positional encoding for odd indices\n",
    "    odd_indices = tf.cast(tf.range(1, d_model, 2), dtype=tf.float32)  # Cast to float32\n",
    "    odd_angles = tf.pow(10000.0, odd_indices / d_model)\n",
    "    PE_odd = tf.cos(tf.einsum('ij,k->ijk', obs_time, 1 / odd_angles))\n",
    "\n",
    "    # Combine even and odd positional encodings\n",
    "    PE = tf.concat([PE_even, PE_odd], axis=-1)\n",
    "\n",
    "    return PE\n"
   ],
   "id": "b20a4d1cd829cf43",
   "outputs": [],
   "execution_count": 123
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-29T19:16:03.342445Z",
     "start_time": "2024-11-29T19:16:03.336884Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Check the data type of a tensor (mask)\n",
    "if mask.dtype == tf.bool:\n",
    "    print(\"The mask is of type bool.\")\n",
    "elif mask.dtype == tf.float32:\n",
    "    print(\"The mask is of type float32.\")\n",
    "else:\n",
    "    print(f\"The mask is of type {mask.dtype}.\")\n"
   ],
   "id": "28b6622354b6bad4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mask is of type bool.\n"
     ]
    }
   ],
   "execution_count": 126
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-29T19:16:04.833892Z",
     "start_time": "2024-11-29T19:16:04.831727Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"Mask dtype:\", mask.dtype)\n",
    "print(\"Mask shape:\", mask.shape)\n"
   ],
   "id": "b604e83735e41d23",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mask dtype: <dtype: 'bool'>\n",
      "Mask shape: (312, 16)\n"
     ]
    }
   ],
   "execution_count": 127
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-29T19:16:09.072736Z",
     "start_time": "2024-11-29T19:16:09.069064Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Configuration for PBC2 dataset\n",
    "d_long = 1           # Univariate longitudinal outcome\n",
    "d_base = 3           # Baseline covariates (age, sex, drug, and splines for year)\n",
    "d_model = 32         # Internal representation dimension\n",
    "nhead = 4            # 4 attention heads (divides d_model evenly)\n",
    "num_decoder_layers = 3  # Three stacked decoder layers\n",
    "dropout = 0.2        # 20% dropout to prevent overfitting\n"
   ],
   "id": "2a88fa3bd0c95d98",
   "outputs": [],
   "execution_count": 128
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-29T19:16:18.144970Z",
     "start_time": "2024-11-29T19:16:18.132237Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# Decoder Layer\n",
    "class DecoderLayer(layers.Layer):\n",
    "    def __init__(self, d_model, nhead, dropout):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "        self.mha = layers.MultiHeadAttention(num_heads=nhead, key_dim=d_model)\n",
    "        self.dropout1 = layers.Dropout(dropout)\n",
    "        self.norm1 = layers.LayerNormalization()\n",
    "        self.ffn = tf.keras.Sequential([\n",
    "            layers.Dense(d_model * 4, activation='relu'),\n",
    "            layers.Dense(d_model)\n",
    "        ])\n",
    "        self.dropout2 = layers.Dropout(dropout)\n",
    "        self.norm2 = layers.LayerNormalization()\n",
    "\n",
    "    def call(self, q, k, v, mask, training=False):\n",
    "         # Convert mask to float32 for compatibility\n",
    "        mask = tf.cast(mask, dtype=tf.float32)\n",
    "        # Multi-head attention\n",
    "        attn_output = self.mha(query=q, key=k, value=v, attention_mask=mask)\n",
    "        attn_output = self.dropout1(attn_output, training=training)\n",
    "        out1 = self.norm1(q + attn_output)  # Add & Norm\n",
    "\n",
    "        # Feed-forward network\n",
    "        ffn_output = self.ffn(out1)\n",
    "        ffn_output = self.dropout2(ffn_output, training=training)\n",
    "        return self.norm2(out1 + ffn_output)  # Add & Norm\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Decoder Block\n",
    "class Decoder(Model):\n",
    "    def __init__(self, d_long, d_base, d_model, nhead, num_decoder_layers, dropout):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.embedding = tf.keras.Sequential([\n",
    "            layers.Dense(d_model, activation='relu'),\n",
    "            layers.Dropout(0.2),\n",
    "            layers.LayerNormalization(),\n",
    "            layers.Dense(d_model)\n",
    "        ])\n",
    "        self.decoder_layers = [DecoderLayer(d_model, nhead, dropout) for _ in range(num_decoder_layers)]\n",
    "\n",
    "    def call(self, long, base, mask, obs_time, training=False):\n",
    "        # Concatenate longitudinal and baseline data\n",
    "        x = tf.concat([long, base], axis=-1)\n",
    "\n",
    "        # Linear Embedding\n",
    "        x = self.embedding(x)\n",
    "\n",
    "        # Positional Embedding\n",
    "        pos_enc = positional_encoding(tf.shape(x)[0], tf.shape(x)[1], tf.shape(x)[2], obs_time)\n",
    "        x += pos_enc\n",
    "        \n",
    "         # Convert mask to float32 for compatibility\n",
    "        mask = tf.cast(mask, dtype=tf.float32)\n",
    "        \n",
    "        # Decoder Layers\n",
    "        for layer in self.decoder_layers:\n",
    "            x = layer(x, x, x, mask, training=training)\n",
    "        return x\n",
    "    \n",
    "\n",
    "\n",
    "# Prediction Decoder Block\n",
    "class DecoderP(Model):\n",
    "    def __init__(self, d_model, nhead, num_decoder_layers, dropout):\n",
    "        super(DecoderP, self).__init__()\n",
    "        self.decoder_layers = [DecoderLayer(d_model, nhead, dropout) for _ in range(num_decoder_layers)]\n",
    "\n",
    "    def call(self, q, kv, mask, pred_time, training=False):\n",
    "        # Positional Embedding\n",
    "        pos_enc = positional_encoding(tf.shape(q)[0], tf.shape(q)[1], tf.shape(q)[2], pred_time)\n",
    "        q += pos_enc\n",
    "\n",
    "        # Decoder Layers\n",
    "        for layer in self.decoder_layers:\n",
    "            q = layer(q, kv, kv, mask, training=training)\n",
    "        return q\n",
    "\n",
    "# Full Transformer Model\n",
    "class Transformer(Model):\n",
    "    def __init__(self, d_long, d_base, d_model=32, nhead=4, num_decoder_layers=3, dropout=0.2):\n",
    "        super(Transformer, self).__init__()\n",
    "        self.decoder = Decoder(d_long, d_base, d_model, nhead, num_decoder_layers, dropout)\n",
    "        self.decoder_pred = DecoderP(d_model, nhead, 1, dropout)\n",
    "        self.long_out = layers.Dense(d_long)\n",
    "        self.surv_out = layers.Dense(1, activation='sigmoid')\n",
    "\n",
    "    def call(self, long, base, mask, obs_time, pred_time, training=False):\n",
    "        x = self.decoder(long, base, mask, obs_time, training=training)\n",
    "        x = self.decoder_pred(x, x, mask, pred_time, training=training)\n",
    "        long_pred = self.long_out(x)\n",
    "        surv_pred = self.surv_out(x)\n",
    "        return long_pred, surv_pred\n",
    "\n",
    "\n"
   ],
   "id": "b66ae5880990fca6",
   "outputs": [],
   "execution_count": 129
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-29T19:22:18.552007Z",
     "start_time": "2024-11-29T19:22:18.545832Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Print the shapes of the input tensors\n",
    "print(\"Shape of Longitudinal Data (x_long):\", x_long.shape)\n",
    "print(\"Shape of Baseline Covariates (x_base):\", x_base.shape)\n",
    "print(\"Shape of Mask (mask):\", mask.shape)\n",
    "print(\"Shape of Observation Time (obs_time):\", obs_time.shape)\n",
    "print(\"Shape of Prediction Time (pred_time):\", pred_time.shape)\n"
   ],
   "id": "9c9758bbad2d10e6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Longitudinal Data (x_long): (312, 16, 1)\n",
      "Shape of Baseline Covariates (x_base): (312, 16, 9)\n",
      "Shape of Mask (mask): (312, 16)\n",
      "Shape of Observation Time (obs_time): (312, 16)\n",
      "Shape of Prediction Time (pred_time): (312, 16)\n"
     ]
    }
   ],
   "execution_count": 130
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-29T19:23:34.621131Z",
     "start_time": "2024-11-29T19:23:33.609007Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Generate the input tensors from PBC2 dataset\n",
    "x_long, x_base, mask, event_tensor, time_tensor, obs_time = get_tensors(df)\n",
    "\n",
    "# Define prediction times (can reuse `obs_time` for simplicity)\n",
    "pred_time = obs_time\n"
   ],
   "id": "1185b8d04dbacb37",
   "outputs": [],
   "execution_count": 131
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-29T19:23:49.192584Z",
     "start_time": "2024-11-29T19:23:49.123839Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Initialize the Transformer model\n",
    "transformer = Transformer(\n",
    "    d_long=d_long,\n",
    "    d_base=d_base,\n",
    "    d_model=d_model,\n",
    "    nhead=nhead,\n",
    "    num_decoder_layers=num_decoder_layers,\n",
    "    dropout=dropout\n",
    ")\n"
   ],
   "id": "c64bbfea78226e17",
   "outputs": [],
   "execution_count": 132
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-29T19:24:15.361511Z",
     "start_time": "2024-11-29T19:24:15.220949Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Pass inputs through the Transformer model\n",
    "long_pred, surv_pred = transformer(\n",
    "    long=x_long,\n",
    "    base=x_base,\n",
    "    mask=mask,\n",
    "    obs_time=obs_time,\n",
    "    pred_time=pred_time,\n",
    "    training=False\n",
    ")\n"
   ],
   "id": "3cfdbfa84887bd36",
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Exception encountered when calling Decoder.call().\n\n\u001B[1m`x` and `y` must have the same dtype, got tf.float32 != tf.int32.\u001B[0m\n\nArguments received by Decoder.call():\n   long=tf.Tensor(shape=(312, 16, 1), dtype=float32)\n   base=tf.Tensor(shape=(312, 16, 15), dtype=float32)\n   mask=tf.Tensor(shape=(312, 16), dtype=bool)\n   obs_time=tf.Tensor(shape=(312, 16), dtype=float32)\n   training=False",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[133], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# Pass inputs through the Transformer model\u001B[39;00m\n\u001B[0;32m----> 2\u001B[0m long_pred, surv_pred \u001B[38;5;241m=\u001B[39m transformer(\n\u001B[1;32m      3\u001B[0m     long\u001B[38;5;241m=\u001B[39mx_long,\n\u001B[1;32m      4\u001B[0m     base\u001B[38;5;241m=\u001B[39mx_base,\n\u001B[1;32m      5\u001B[0m     mask\u001B[38;5;241m=\u001B[39mmask,\n\u001B[1;32m      6\u001B[0m     obs_time\u001B[38;5;241m=\u001B[39mobs_time,\n\u001B[1;32m      7\u001B[0m     pred_time\u001B[38;5;241m=\u001B[39mpred_time,\n\u001B[1;32m      8\u001B[0m     training\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[1;32m      9\u001B[0m )\n",
      "File \u001B[0;32m~/miniconda3/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py:122\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    119\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n\u001B[1;32m    120\u001B[0m     \u001B[38;5;66;03m# To get the full stack trace, call:\u001B[39;00m\n\u001B[1;32m    121\u001B[0m     \u001B[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001B[39;00m\n\u001B[0;32m--> 122\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m e\u001B[38;5;241m.\u001B[39mwith_traceback(filtered_tb) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    123\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m    124\u001B[0m     \u001B[38;5;28;01mdel\u001B[39;00m filtered_tb\n",
      "Cell \u001B[0;32mIn[129], line 94\u001B[0m, in \u001B[0;36mTransformer.call\u001B[0;34m(self, long, base, mask, obs_time, pred_time, training)\u001B[0m\n\u001B[1;32m     93\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcall\u001B[39m(\u001B[38;5;28mself\u001B[39m, long, base, mask, obs_time, pred_time, training\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m):\n\u001B[0;32m---> 94\u001B[0m     x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdecoder(long, base, mask, obs_time, training\u001B[38;5;241m=\u001B[39mtraining)\n\u001B[1;32m     95\u001B[0m     x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdecoder_pred(x, x, mask, pred_time, training\u001B[38;5;241m=\u001B[39mtraining)\n\u001B[1;32m     96\u001B[0m     long_pred \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlong_out(x)\n",
      "Cell \u001B[0;32mIn[129], line 55\u001B[0m, in \u001B[0;36mDecoder.call\u001B[0;34m(self, long, base, mask, obs_time, training)\u001B[0m\n\u001B[1;32m     52\u001B[0m x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39membedding(x)\n\u001B[1;32m     54\u001B[0m \u001B[38;5;66;03m# Positional Embedding\u001B[39;00m\n\u001B[0;32m---> 55\u001B[0m pos_enc \u001B[38;5;241m=\u001B[39m positional_encoding(tf\u001B[38;5;241m.\u001B[39mshape(x)[\u001B[38;5;241m0\u001B[39m], tf\u001B[38;5;241m.\u001B[39mshape(x)[\u001B[38;5;241m1\u001B[39m], tf\u001B[38;5;241m.\u001B[39mshape(x)[\u001B[38;5;241m2\u001B[39m], obs_time)\n\u001B[1;32m     56\u001B[0m x \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m pos_enc\n\u001B[1;32m     58\u001B[0m  \u001B[38;5;66;03m# Convert mask to float32 for compatibility\u001B[39;00m\n",
      "Cell \u001B[0;32mIn[123], line 35\u001B[0m, in \u001B[0;36mpositional_encoding\u001B[0;34m(batch_size, length, d_model, obs_time)\u001B[0m\n\u001B[1;32m     33\u001B[0m \u001B[38;5;66;03m# Compute positional encoding for even indices\u001B[39;00m\n\u001B[1;32m     34\u001B[0m even_indices \u001B[38;5;241m=\u001B[39m tf\u001B[38;5;241m.\u001B[39mcast(tf\u001B[38;5;241m.\u001B[39mrange(\u001B[38;5;241m0\u001B[39m, d_model, \u001B[38;5;241m2\u001B[39m), dtype\u001B[38;5;241m=\u001B[39mtf\u001B[38;5;241m.\u001B[39mfloat32)  \u001B[38;5;66;03m# Cast to float32\u001B[39;00m\n\u001B[0;32m---> 35\u001B[0m even_angles \u001B[38;5;241m=\u001B[39m tf\u001B[38;5;241m.\u001B[39mpow(\u001B[38;5;241m10000.0\u001B[39m, even_indices \u001B[38;5;241m/\u001B[39m d_model)\n\u001B[1;32m     36\u001B[0m PE_even \u001B[38;5;241m=\u001B[39m tf\u001B[38;5;241m.\u001B[39msin(tf\u001B[38;5;241m.\u001B[39meinsum(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mij,k->ijk\u001B[39m\u001B[38;5;124m'\u001B[39m, obs_time, \u001B[38;5;241m1\u001B[39m \u001B[38;5;241m/\u001B[39m even_angles))\n\u001B[1;32m     38\u001B[0m \u001B[38;5;66;03m# Compute positional encoding for odd indices\u001B[39;00m\n",
      "\u001B[0;31mTypeError\u001B[0m: Exception encountered when calling Decoder.call().\n\n\u001B[1m`x` and `y` must have the same dtype, got tf.float32 != tf.int32.\u001B[0m\n\nArguments received by Decoder.call():\n   long=tf.Tensor(shape=(312, 16, 1), dtype=float32)\n   base=tf.Tensor(shape=(312, 16, 15), dtype=float32)\n   mask=tf.Tensor(shape=(312, 16), dtype=bool)\n   obs_time=tf.Tensor(shape=(312, 16), dtype=float32)\n   training=False"
     ]
    }
   ],
   "execution_count": 133
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-29T19:26:21.295997Z",
     "start_time": "2024-11-29T19:26:21.255274Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"x dtype:\", x.dtype)\n",
    "print(\"y dtype:\", y.dtype)\n"
   ],
   "id": "c95412ecd1457d1f",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[134], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mx dtype:\u001B[39m\u001B[38;5;124m\"\u001B[39m, x\u001B[38;5;241m.\u001B[39mdtype)\n\u001B[1;32m      2\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124my dtype:\u001B[39m\u001B[38;5;124m\"\u001B[39m, y\u001B[38;5;241m.\u001B[39mdtype)\n",
      "\u001B[0;31mNameError\u001B[0m: name 'x' is not defined"
     ]
    }
   ],
   "execution_count": 134
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "dbda6874d423fa0b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def long_loss(yhat, y, mask):\n",
    "    \"\"\"\n",
    "    Loss for longitudinal outcomes (mean squared error with masking).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    yhat : tf.Tensor\n",
    "        Predicted longitudinal outcomes, shape (batch_size, seq_len, num_features).\n",
    "    y : tf.Tensor\n",
    "        True longitudinal outcomes, shape (batch_size, seq_len, num_features).\n",
    "    mask : tf.Tensor\n",
    "        Mask indicating valid data (1 for valid, 0 for padding), shape (batch_size, seq_len).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    loss : tf.Tensor\n",
    "        Scalar representing the mean loss for valid elements.\n",
    "    \"\"\"\n",
    "    # Expand the mask to match the number of features\n",
    "    mask = tf.expand_dims(mask, axis=-1)  # Shape: (batch_size, seq_len, 1)\n",
    "    \n",
    "    # Compute MSE loss element-wise\n",
    "    loss = tf.keras.losses.mean_squared_error(y, yhat)  # Shape: (batch_size, seq_len, num_features)\n",
    "    \n",
    "    # Apply the mask to exclude padding\n",
    "    loss *= tf.cast(mask, tf.float32)\n",
    "    \n",
    "    # Normalize the loss by the number of valid elements\n",
    "    loss = tf.reduce_sum(loss) / tf.reduce_sum(mask)\n",
    "    return loss\n"
   ],
   "id": "f0d6f05f046fb29b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "\n",
    "def surv_loss(surv_pred, mask, event):\n",
    "    \"\"\"\n",
    "    Loss for survival predictions (negative log-likelihood).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    surv_pred : tf.Tensor\n",
    "        Predicted survival probabilities, shape (batch_size, seq_len).\n",
    "    mask : tf.Tensor\n",
    "        Mask indicating valid data (1 for valid, 0 for padding), shape (batch_size, seq_len).\n",
    "    event : tf.Tensor\n",
    "        Event indicators (1 if event occurred, 0 otherwise), shape (batch_size).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    loss : tf.Tensor\n",
    "        Scalar representing the mean negative log-likelihood loss.\n",
    "    \"\"\"\n",
    "    # Convert mask and event tensors to NumPy arrays for indexing\n",
    "    mask_np = mask.numpy()\n",
    "    event_np = event.numpy()\n",
    "\n",
    "    # Exclude the first time step and reverse the mask\n",
    "    mask_out = mask_np[:, 1:]\n",
    "    mask_rev = mask_out[:, ::-1]\n",
    "    \n",
    "    # Determine the index of the last valid time step (event time index)\n",
    "    event_time_index = mask_out.shape[1] - np.argmax(mask_rev, axis=1) - 1\n",
    "    \n",
    "    # Create event filter (e_filter) and survival filter (s_filter)\n",
    "    e_filter = np.zeros_like(mask_out)\n",
    "    for row_idx, event_occurred in enumerate(event_np):\n",
    "        if event_occurred:\n",
    "            e_filter[row_idx, event_time_index[row_idx]] = 1\n",
    "    s_filter = mask_out - e_filter\n",
    "\n",
    "    # Convert filters to TensorFlow tensors\n",
    "    s_filter = tf.convert_to_tensor(s_filter, dtype=tf.float32)\n",
    "    e_filter = tf.convert_to_tensor(e_filter, dtype=tf.float32)\n",
    "    \n",
    "    # Calculate negative log-likelihood\n",
    "    surv_pred = tf.squeeze(surv_pred)  # Remove unnecessary dimensions\n",
    "    nll_loss = (\n",
    "        tf.math.log(surv_pred) * s_filter +\n",
    "        tf.math.log(1 - surv_pred) * e_filter\n",
    "    )\n",
    "    \n",
    "    # Normalize loss by the total number of valid observations\n",
    "    nll_loss = tf.reduce_sum(nll_loss) / tf.reduce_sum(mask_out)\n",
    "    return -nll_loss\n"
   ],
   "id": "5c275b95d1296f2a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "7beb42eee8b87551",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score\n"
   ],
   "id": "938c15e6fabbf3d6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def get_integrated(x, times):\n",
    "    \"\"\"\n",
    "    Compute the integral of a time-dependent metric using the trapezoidal rule.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    x : np.array\n",
    "        Metric values at different times.\n",
    "    times : np.array\n",
    "        Corresponding time points.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        Integrated metric value normalized by the time range.\n",
    "    \"\"\"\n",
    "    return np.trapz(x, times) / (max(times) - min(times))\n"
   ],
   "id": "4c17f75d2de00917",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def AUC(surv_probs, event, time, pred_times):\n",
    "    \"\"\"\n",
    "    Compute AUC and integrated AUC for survival probabilities.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    surv_probs : np.array\n",
    "        Predicted survival probabilities (shape: [num_samples, num_pred_times]).\n",
    "    event : np.array\n",
    "        Event indicators (1 for event, 0 for censoring).\n",
    "    time : np.array\n",
    "        Event or censoring times.\n",
    "    pred_times : np.array\n",
    "        Times at which predictions are made.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    auc : np.array\n",
    "        AUC values at each prediction time.\n",
    "    iauc : float\n",
    "        Integrated AUC over the prediction times.\n",
    "    \"\"\"\n",
    "    auc = []\n",
    "    for t in range(surv_probs.shape[1]):\n",
    "        valid_indices = time >= pred_times[t]  # Only consider valid events at this prediction time\n",
    "        if valid_indices.sum() > 1:  # Ensure at least two valid samples\n",
    "            auc.append(roc_auc_score(event[valid_indices], surv_probs[valid_indices, t]))\n",
    "        else:\n",
    "            auc.append(np.nan)  # Undefined AUC if not enough data\n",
    "\n",
    "    auc = np.array(auc)\n",
    "    iauc = get_integrated(auc, pred_times)\n",
    "    return auc, iauc\n"
   ],
   "id": "1f5b4d20d25f8aaf",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def Brier(surv_probs, event, time, event_train, time_train, LT, pred_windows):\n",
    "    \"\"\"\n",
    "    Compute Brier score and integrated Brier score.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    surv_probs : np.array\n",
    "        Predicted survival probabilities (shape: [num_samples, num_pred_times]).\n",
    "    event : np.array\n",
    "        Event indicators for test data.\n",
    "    time : np.array\n",
    "        Event or censoring times for test data.\n",
    "    event_train : np.array\n",
    "        Event indicators for training data.\n",
    "    time_train : np.array\n",
    "        Event or censoring times for training data.\n",
    "    LT : float\n",
    "        Landmark time.\n",
    "    pred_windows : np.array\n",
    "        Prediction time windows.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    bs : np.array\n",
    "        Brier scores at each prediction window.\n",
    "    ibs : float\n",
    "        Integrated Brier score over the prediction windows.\n",
    "    \"\"\"\n",
    "    bs = []\n",
    "    for t in pred_windows:\n",
    "        valid_indices = (time >= LT) & (time <= t)\n",
    "        if valid_indices.sum() > 0:\n",
    "            y_true = (event[valid_indices] == 1).astype(float)\n",
    "            y_pred = 1 - surv_probs[valid_indices, np.searchsorted(pred_windows, t)]\n",
    "            bs.append(np.mean((y_true - y_pred) ** 2))\n",
    "        else:\n",
    "            bs.append(np.nan)  # Undefined Brier score if not enough data\n",
    "\n",
    "    bs = np.array(bs)\n",
    "    ibs = get_integrated(bs, pred_windows)\n",
    "    return bs, ibs\n"
   ],
   "id": "9d35137928176a07",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def MSE(y, yhat):\n",
    "    \"\"\"\n",
    "    Compute Mean Squared Error for longitudinal outcomes.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    y : np.array\n",
    "        True values (shape: [num_samples, num_time_steps]).\n",
    "    yhat : np.array\n",
    "        Predicted values (shape: [num_samples, num_time_steps]).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    mse : float\n",
    "        Mean squared error across subjects and time.\n",
    "    \"\"\"\n",
    "    mse = np.square(y - yhat)\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.filterwarnings(action='ignore', message='Mean of empty slice')\n",
    "        mse = np.nanmean(mse, axis=1)  # Average over time\n",
    "    mse = np.nanmean(mse, axis=0)  # Average over subjects\n",
    "    return mse\n"
   ],
   "id": "44a6c775ae0e1c5c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "1d171e5490dee375",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
